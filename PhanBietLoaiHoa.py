# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QWKpfDZTjWPq7h8PExdPfg8kh1ualvgw
"""

# -*- coding: utf-8 -*-
# Pipeline ho√†n ch·ªânh: th√™m hi·ªÉn th·ªã ·∫£nh test + visualization + GUI
import os, zipfile, json, shutil, math
from collections import Counter
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image, UnidentifiedImageError
import warnings
warnings.filterwarnings('ignore')

# ML libs
from skimage.color import rgb2gray
from skimage.feature import hog
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# TF / Keras
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Extras for visualization
from sklearn.decomposition import PCA
from glob import glob

# GUI
import tkinter as tk
from tkinter import filedialog, ttk

# -----------------------------
# C·∫•u h√¨nh nhanh
# -----------------------------
IMG_SIZE = (96, 96)           # k√≠ch th∆∞·ªõc ·∫£nh (c√≥ th·ªÉ tƒÉng n·∫øu c√≥ GPU)
BATCH = 32
EPOCHS = 5                    # demo; tƒÉng n·∫øu c√≥ GPU/time
HOG_MAX_PER_CLASS = 50
HOG_ORIENT = 9

# ƒê∆∞·ªùng d·∫´n zip c√≥ th·ªÉ kh√°c t√πy b·∫°n
candidates_zip = [
    "/mnt/data/archive.zip",
    "/content/archive.zip",
    "./archive.zip",
    "/mnt/data/flower_data.zip",
    "/content/drive/MyDrive/archive.zip",
]
default_extract = "/content/flowers"

# --- t√¨m/gi·∫£i n√©n d·ªØ li·ªáu (b·∫£n tr∆∞·ªõc c·ªßa b·∫°n) ---
def try_mount_colab_drive():
    try:
        from google.colab import drive
        drive.mount('/content/drive', force_remount=False)
        return True
    except Exception:
        return False

def find_and_prepare_data():
    zip_found = None
    for p in candidates_zip:
        if os.path.exists(p):
            zip_found = p
            break
    if zip_found is None:
        try_mount_colab_drive()
        for p in candidates_zip:
            if os.path.exists(p):
                zip_found = p
                break
    extract_root = default_extract
    if zip_found:
        print("T√¨m th·∫•y file zip:", zip_found)
        os.makedirs(extract_root, exist_ok=True)
        try:
            with zipfile.ZipFile(zip_found, 'r') as z:
                z.extractall(extract_root)
            print("ƒê√£ gi·∫£i n√©n v√†o:", extract_root)
        except Exception as e:
            print("L·ªói khi gi·∫£i n√©n:", e)
    else:
        print("Kh√¥ng t√¨m th·∫•y file zip trong c√°c ƒë∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh.")
    possible_dirs = [
        os.path.join(extract_root, "flower_data"),
        os.path.join(extract_root, "flowers", "flower_data"),
        "./flower_data",
        "/content/flowers/flower_data",
        "/mnt/data/flower_data"
    ]
    for d in possible_dirs:
        if os.path.exists(d):
            return d
    if os.path.exists(extract_root):
        print("C√°c th∆∞ m·ª•c trong", extract_root, ":", os.listdir(extract_root))
    return None

data_dir = find_and_prepare_data()
if data_dir is None:
    raise FileNotFoundError("Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c 'flower_data'.")

thu_train = os.path.join(data_dir, "train")
thu_val   = os.path.join(data_dir, "valid")
thu_test  = os.path.join(data_dir, "test")
if not (os.path.exists(thu_train) and os.path.exists(thu_val)):
    raise FileNotFoundError("Kh√¥ng t√¨m th·∫•y c·∫•u tr√∫c train/valid trong dataset.")

cat2name_path = os.path.join(data_dir, "cat_to_name.json")
cat2name = {}
if os.path.exists(cat2name_path):
    with open(cat2name_path, 'r', encoding='utf-8') as f:
        cat2name = json.load(f)
    print("ƒê√£ load cat_to_name.json.")
else:
    print("Kh√¥ng th·∫•y cat_to_name.json; d√πng t√™n folder l√†m label.")

# -----------------------------
# 1) EDA c∆° b·∫£n & hi·ªÉn th·ªã m·∫´u
# -----------------------------
def count_images(folder):
    res = {}
    for c in sorted(os.listdir(folder)):
        p = os.path.join(folder, c)
        if os.path.isdir(p):
            files = [f for f in os.listdir(p) if not f.startswith('.') and os.path.isfile(os.path.join(p,f))]
            res[c] = len(files)
    return res

train_counts = count_images(thu_train)
val_counts = count_images(thu_val)
test_counts = count_images(thu_test) if os.path.exists(thu_test) else {}

print("S·ªë l·ªõp (train):", len(train_counts))
print("T·ªïng ·∫£nh train:", sum(train_counts.values()))
print("T·ªïng ·∫£nh valid:", sum(val_counts.values()))
print("T·ªïng ·∫£nh test (n·∫øu test chia folder):", sum(test_counts.values()) if test_counts else 0)

# ======================================
# Tr·ª±c quan h√≥a to√†n b·ªô d·ªØ li·ªáu
# ======================================
def plot_distribution(counts_dict, title):
    classes = list(counts_dict.keys())
    values = [counts_dict[c] for c in classes]

    plt.figure(figsize=(max(12, len(classes)//4), 6))
    sns.barplot(x=classes, y=values, color="skyblue")
    plt.xticks(rotation=90)
    plt.title(title)
    plt.xlabel("Class ID")
    plt.ylabel("S·ªë ·∫£nh")
    plt.show()

plot_distribution(train_counts, "Ph√¢n ph·ªëi s·ªë ·∫£nh trong t·∫≠p Train")
plot_distribution(val_counts, "Ph√¢n ph·ªëi s·ªë ·∫£nh trong t·∫≠p Validation")
if test_counts:
    plot_distribution(test_counts, "Ph√¢n ph·ªëi s·ªë ·∫£nh trong t·∫≠p Test")


# show samples
def show_samples(folder, n_classes=6, n_per_class=3):
    classes = sorted([c for c in os.listdir(folder) if os.path.isdir(os.path.join(folder,c))])[:n_classes]
    plt.figure(figsize=(n_per_class*3, n_classes*3))
    idx = 1
    for c in classes:
        p = os.path.join(folder, c)
        files = [f for f in os.listdir(p) if not f.startswith('.')][:n_per_class]
        for f in files:
            try:
                im = Image.open(os.path.join(p,f)).convert('RGB').resize(IMG_SIZE)
                plt.subplot(n_classes, n_per_class, idx)
                plt.imshow(im)
                plt.axis('off')
                if idx % n_per_class == 1:
                    plt.title(cat2name.get(c, c))
                idx += 1
            except Exception:
                idx += 1
    plt.suptitle("·∫¢nh m·∫´u (m·ªói h√†ng 1 l·ªõp)")
    plt.show()

show_samples(thu_train)

# -----------------------------
# 2) Generators
# -----------------------------
train_aug = ImageDataGenerator(rescale=1./255,
                               rotation_range=25, width_shift_range=0.12,
                               height_shift_range=0.12, zoom_range=0.15,
                               horizontal_flip=True, brightness_range=(0.8,1.2),
                               fill_mode='nearest')
val_aug = ImageDataGenerator(rescale=1./255)
test_aug = ImageDataGenerator(rescale=1./255)

train_gen = train_aug.flow_from_directory(thu_train, target_size=IMG_SIZE, batch_size=BATCH, class_mode='categorical', shuffle=True)
val_gen   = val_aug.flow_from_directory(thu_val, target_size=IMG_SIZE, batch_size=BATCH, class_mode='categorical', shuffle=False)

# x·ª≠ l√Ω test: n·∫øu test ch∆∞a chia folder -> gom v√†o unknown subfolder (nh∆∞ b·∫°n ƒë√£ l√†m)
test_has_labels = False
if os.path.exists(thu_test):
    subdirs = [d for d in os.listdir(thu_test) if os.path.isdir(os.path.join(thu_test, d))]
    if len(subdirs) > 0:
        test_gen = test_aug.flow_from_directory(thu_test, target_size=IMG_SIZE, batch_size=BATCH, class_mode='categorical', shuffle=False)
        test_has_labels = True
    else:
        fake = os.path.join(thu_test, "unknown")
        os.makedirs(fake, exist_ok=True)
        moved = 0
        exts = {'.jpg','.jpeg','.png','.bmp','.tif','.tiff'}
        for f in os.listdir(thu_test):
            fp = os.path.join(thu_test, f)
            if os.path.isfile(fp) and (os.path.splitext(f)[1].lower() in exts):
                try:
                    shutil.move(fp, os.path.join(fake, f))
                    moved += 1
                except Exception:
                    pass
        print(f"ƒê√£ gom {moved} ·∫£nh test v√†o {fake}; test kh√¥ng c√≥ nh√£n.")
        # class_mode=None ƒë·ªÉ generator tr·∫£ v·ªÅ ch·ªâ images khi predict
        test_gen = test_aug.flow_from_directory(thu_test, target_size=IMG_SIZE, batch_size=BATCH, class_mode=None, shuffle=False)
        test_has_labels = False
else:
    print("Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c test; test_gen=None")
    test_gen = None

# -----------------------------
# 3) (t√πy) tr√≠ch xu·∫•t HOG - n·∫øu c·∫ßn
# -----------------------------
def extract_hog_from_folder(folder, max_per_class=HOG_MAX_PER_CLASS):
    X, y = [], []
    failed = 0
    classes = sorted([c for c in os.listdir(folder) if os.path.isdir(os.path.join(folder,c))])
    for c in classes:
        p = os.path.join(folder, c)
        files = [f for f in os.listdir(p) if not f.startswith('.')][:max_per_class]
        for f in files:
            fp = os.path.join(p,f)
            try:
                im = Image.open(fp).convert('RGB').resize(IMG_SIZE)
                gray = rgb2gray(np.array(im))
                feat = hog(gray, orientations=HOG_ORIENT, pixels_per_cell=(8,8), cells_per_block=(2,2), block_norm="L2-Hys", visualize=False)
                X.append(feat)
                y.append(c)
            except (UnidentifiedImageError, OSError, ValueError):
                failed += 1
                continue
    X = np.array(X); y = np.array(y)
    print(f"HOG: ƒë·ªçc {len(X)} ·∫£nh, l·ªói {failed} file trong {folder}")
    return X, y

print("B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t HOG (gi·ªõi h·∫°n per-class)...")
X_hog_train, y_hog_train = extract_hog_from_folder(thu_train, max_per_class=HOG_MAX_PER_CLASS)
X_hog_val, y_hog_val = extract_hog_from_folder(thu_val, max_per_class=HOG_MAX_PER_CLASS)
hog_ok = (len(X_hog_train) > 0 and len(X_hog_val) > 0)

if hog_ok:
    le = LabelEncoder().fit(y_hog_train)
    y_train_enc = le.transform(y_hog_train)
    y_val_enc = le.transform(y_hog_val)
    svm = LinearSVC(max_iter=5000, dual=False)
    svm.fit(X_hog_train, y_train_enc)
    y_pred_val_hog = svm.predict(X_hog_val)
    print("HOG+SVM tr√™n validation:")
    print(classification_report(y_val_enc, y_pred_val_hog, target_names=le.classes_))
    cm_hog = confusion_matrix(y_val_enc, y_pred_val_hog)
    plt.figure(figsize=(10,8))
    sns.heatmap(cm_hog, cmap='Blues')
    plt.title("Confusion Matrix (HOG+SVM)")
    plt.show()
    acc_hog = accuracy_score(y_val_enc, y_pred_val_hog)
else:
    print("Kh√¥ng ƒë·ªß d·ªØ li·ªáu HOG ƒë·ªÉ hu·∫•n luy·ªán/ƒë√°nh gi√°.")
    acc_hog = None

# -----------------------------
# 4) Transfer Learning (VGG16)
# -----------------------------
print("X√¢y d·ª±ng model VGG16 transfer learning...")
base = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))
for layer in base.layers:
    layer.trainable = False
# unfreeze block5 for light fine-tune
for layer in base.layers:
    if layer.name.startswith('block5_'):
        layer.trainable = True

x = GlobalAveragePooling2D()(base.output)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
out = Dense(train_gen.num_classes, activation='softmax')(x)
model = Model(inputs=base.input, outputs=out)
model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

es = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
ckp = ModelCheckpoint("best_vgg.keras", monitor='val_loss', save_best_only=True)

print("B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán VGG16 (epochs =", EPOCHS, ") ...")
history = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS, callbacks=[es, ckp])

# Learning curves
plt.figure(); plt.plot(history.history['accuracy'], label='train_acc'); plt.plot(history.history['val_accuracy'], label='val_acc'); plt.legend(); plt.title("Accuracy"); plt.show()
plt.figure(); plt.plot(history.history['loss'], label='train_loss'); plt.plot(history.history['val_loss'], label='val_loss'); plt.legend(); plt.title("Loss"); plt.show()

# -----------------------------
# 5) ƒê√°nh gi√° VGG16 tr√™n validation (chi ti·∫øt)
# -----------------------------
val_steps = math.ceil(val_gen.samples / BATCH)
ypred_p = model.predict(val_gen, steps=val_steps, verbose=1)
ypred = np.argmax(ypred_p, axis=1)
ytrue = val_gen.classes
idx2class = {v:k for k,v in val_gen.class_indices.items()}
ytrue_names = [idx2class[i] for i in ytrue]
ypred_names = [idx2class[i] for i in ypred]

print("VGG16 tr√™n validation:")
print(classification_report(ytrue_names, ypred_names, target_names=[idx2class[i] for i in range(len(idx2class))]))
cm_vgg = confusion_matrix(ytrue_names, ypred_names, labels=[idx2class[i] for i in range(len(idx2class))])
plt.figure(figsize=(12,10))
sns.heatmap(cm_vgg, cmap='Blues')
plt.title("Confusion Matrix (VGG16)")
plt.show()
acc_vgg = accuracy_score(ytrue_names, ypred_names)

# -----------------------------
# 6) So s√°nh
# -----------------------------
print("\n--- T√ìM T·∫ÆT K·∫æT QU·∫¢ ---")
if acc_hog is not None:
    print("HOG+SVM validation accuracy:", acc_hog)
print("VGG16 validation accuracy:", acc_vgg)

methods = []
accs = []
if acc_hog is not None:
    methods.append("HOG+SVM"); accs.append(acc_hog)
methods.append("VGG16"); accs.append(acc_vgg)
plt.figure(figsize=(6,4)); sns.barplot(x=methods, y=accs); plt.ylim(0,1); plt.title("So s√°nh accuracy tr√™n validation"); plt.show()

# -----------------------------
# 7) Visualize embeddings (PCA tr√™n feature embedding c·ªßa VGG - l·∫•y subset ƒë·ªÉ nhanh)
# -----------------------------
# T·∫°o model l·∫•y embedding (GlobalAveragePooling output)
embed_model = Model(inputs=model.input, outputs=model.layers[-3].output)  # layer before Dense(256)
# L·∫•y m·ªôt subset t·ª´ validation ƒë·ªÉ v·∫Ω
subset = 500
imgs = []
labels_idx = []
filepaths = val_gen.filepaths
for i in range(min(subset, len(filepaths))):
    imgs.append(img_to_array(Image.open(filepaths[i]).convert('RGB').resize(IMG_SIZE))/255.0)
    labels_idx.append(val_gen.classes[i])
imgs = np.array(imgs)
emb = embed_model.predict(imgs, verbose=0)
pca = PCA(n_components=2)
emb2 = pca.fit_transform(emb)
plt.figure(figsize=(8,6))
scatter = plt.scatter(emb2[:,0], emb2[:,1], c=labels_idx, s=10, cmap='tab20')
plt.title("PCA of embeddings (validation subset)")
plt.colorbar()
plt.show()

# -----------------------------
# 8) Predict tr√™n test & hi·ªÉn th·ªã ·∫£nh + nh√£n d·ª± ƒëo√°n
# -----------------------------
if test_gen is not None:
    print("Predict tr√™n test (s·ªë ·∫£nh):", test_gen.samples)
    steps_test = math.ceil(test_gen.samples / BATCH)
    ypred_test_p = model.predict(test_gen, steps=steps_test, verbose=1)
    ypred_test = np.argmax(ypred_test_p, axis=1)

    # N·∫øu test c√≥ nh√£n (kh√¥ng th∆∞·ªùng trong Oxford), hi·ªÉn th·ªã b√°o c√°o; n·∫øu kh√¥ng c√≥, th√¨ hi·ªÉn th·ªã ·∫£nh + d·ª± ƒëo√°n
    if test_has_labels:
        ytrue_test = test_gen.classes
        idx2class_test = {v:k for k,v in test_gen.class_indices.items()}
        ytrue_test_names = [idx2class_test[i] for i in ytrue_test]
        ypred_test_names = [idx2class_test[i] for i in ypred_test]
        print(classification_report(ytrue_test_names, ypred_test_names, target_names=[idx2class_test[i] for i in range(len(idx2class_test))]))
    else:
        # hi·ªÉn th·ªã grid ·∫£nh & d·ª± ƒëo√°n
        filepaths_test = test_gen.filepaths  # list ƒë∆∞·ªùng d·∫´n file theo th·ª© t·ª± generator
        num_show = min(40, len(filepaths_test))  # s·ªë ·∫£nh hi·ªÉn th·ªã t·ªëi ƒëa
        cols = 5
        rows = math.ceil(num_show / cols)
        plt.figure(figsize=(cols*4, rows*3))
        idx_map = {v:k for k,v in train_gen.class_indices.items()}
        for i in range(num_show):
            fp = filepaths_test[i]
            pred_idx = ypred_test[i]
            pred_class = idx_map.get(pred_idx, str(pred_idx))
            pred_name = cat2name.get(pred_class, pred_class)
            try:
                im = Image.open(fp).convert('RGB')
                plt.subplot(rows, cols, i+1)
                plt.imshow(im.resize((IMG_SIZE[0], IMG_SIZE[1])))
                plt.title(pred_name, fontsize=9)
                plt.axis('off')
            except Exception:
                continue
        plt.suptitle("D·ª± ƒëo√°n m·∫´u tr√™n test (test kh√¥ng c√≥ nh√£n)", fontsize=16)
        plt.tight_layout()
        plt.show()

# -----------------------------
# -----------------------------
# 9) Giao di·ªán Gradio cho d·ª± ƒëo√°n ·∫£nh
# -----------------------------
import gradio as gr

def predict_flower(img):
    # img: ·∫£nh ƒë·∫ßu v√†o (PIL Image t·ª´ gradio)
    img = img.convert('RGB').resize(IMG_SIZE)
    x = np.array(img) / 255.0
    x = np.expand_dims(x, axis=0)
    p = model.predict(x)
    idx = np.argmax(p, axis=1)[0]
    idx2 = {v:k for k,v in train_gen.class_indices.items()}
    cls = idx2.get(idx, str(idx))
    return f"D·ª± ƒëo√°n: {cat2name.get(cls, cls)}"

# t·∫°o giao di·ªán
demo = gr.Interface(
    fn=predict_flower,
    inputs=gr.Image(type="pil", label="T·∫£i ·∫£nh hoa v√†o ƒë√¢y"),
    outputs=gr.Label(label="K·∫øt qu·∫£ d·ª± ƒëo√°n"),
    title="üå∏ Flower Classifier Demo",
    description="Upload m·ªôt ·∫£nh hoa (Oxford 102 Flowers Dataset) v√† xem model d·ª± ƒëo√°n lo√†i hoa n√†o."
)

# ch·∫°y demo
demo.launch(share=True)  # share=True ƒë·ªÉ c√≥ link public n·∫øu mu·ªën